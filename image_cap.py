# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wu5FD59i5_EYRKhX4C_eVPTpjwZKZPDO
"""

import string
import numpy as np
from PIL import Image
import os
from pickle import dump, load
import numpy as np

from keras.applications.xception import Xception, preprocess_input
from keras.preprocessing.image import load_img, img_to_array
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.utils import to_categorical
from keras.layers.merge import add
from keras.models import Model, load_model
from keras.layers import Input, Dense, LSTM, Embedding, Dropout

# small library for seeing the progress of loops.
from tqdm import tqdm_notebook as tqdm
tqdm().pandas()

# Loading a text file into memory

def load_textfile(given_file):
  # open the file in read Mode Only
  file1=open(given_file,'r')
  text_file=file1.read()
  file1.close()
  return text_file


#Get all images with their captions

def get_image_with_caption(given_file):
  #Load the file
  file1=load_textfile(given_file)
  # split given file into list of lines
  caption1=file1.split('\n')
  descriptions={}


  for each_line in caption1[:-1]:
    # image and caption are seprated by tab
    imag,capt=each_line.split('\t')
    if imag[:-2] not in descriptions:
      descriptions[imag[:-2]]=[capt]
    else:
      descriptions[imag[:-2]].append(capt)
  
  return descriptions


# Data cleaning,Removing punctuation,Lower casing,Removing words containing Numbers

def cleaning_data(caption_file):

  for image,caption in caption_file.items():

    for id,img_caption in enumerate(caption):
      img_caption.replace("-"," ")
      temp=img_caption.split()

      #converting to lower_case

      temp=[word.lower() for word in temp]

      #remove punctuation 
      temp=[word.translate(str.maketrans('','',',')) for word in temp]

      # Remove hanging s and a like It,s
      temp=[word for word in temp if(len(word)>1)]

      #Remove words containing numbers
      temp=[word for word in temp if(word.isalpa())]

      #convert back to string
      img_caption=' '.join(temp)

      caption_file[image][id]=img_caption
  
  return caption_file

#build vocabulary of all unique words

def build_vocab(descriptions):
  # all unique words
  vocab=set()

  for key in descriptions.keys():
    [vocab.update(word.split()) for word in descriptions[key]]
    # In each caption split it into words and add them to set
  
  return vocab

# Saving all descriptions in one file

def save_descript(descriptions,filename):
  lines=list()

  for key,temp_list in descriptions.items():
    for temp1 in temp_list:
      lines.append(key+'\t'+temp)

  all_data="\n".join(lines)
  file=open(filename,"w")

  file.write(all_data)
  file.close()

#Preparing our text data by performing data cleaning and other steps mentioned above

dataset_text = "D:\dataflair projects\Project - Image Caption Generator\Flickr_8k_text"
dataset_images = "D:\dataflair projects\Project - Image Caption Generator\Flicker8k_Dataset"

# Preprocessing our data given by flicker.
# Each image has five captions.
# 8092 images and 5*8092 captions are given.

#we prepare our text data
filename = dataset_text + "/" + "Flickr8k.token.txt"

#loading the file that contains all data
#mapping them into descriptions dictionary img to 5 captions

descriptions = all_img_captions(filename)
print("Length of descriptions =" ,len(descriptions))

#cleaning the descriptions
clean_descriptions = cleaning_text(descriptions)

#building vocabulary 
vocabulary = text_vocabulary(clean_descriptions)
print("Length of vocabulary = ", len(vocabulary)+1)

#saving each description to file 
save_descriptions(clean_descriptions, "descriptions.txt")


# We will going to extract features of our dataset images 
# from pretrained model Xception which is already trained on 1000 classes of images.

def extract_features(directory):
  model=Xception(include_top=False,pooling='avg')
  features={}

  for image in tqdm(os.listdir(directory)):
    filename=directory+"/"+image
    final_image=Image.open(filename)
    final_image=Image.resize((299,299))
    final_image=np.expand_dims(image,axis=0)
    final_image=final_image/127.5
    final_image=final_image-1.0

    feature=model.predict(image)

    features[image]=feature

  return features



